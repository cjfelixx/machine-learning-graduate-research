{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "597eb1a4-55af-4a8c-b000-581bbafd3bc3",
   "metadata": {},
   "source": [
    "# Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88a7b5cb-341c-4a9b-b05a-5e6c03a4c9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  8\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from knlms import *\n",
    "from krls import *\n",
    "from krls_rff import *\n",
    "from klms import *\n",
    "from klms_rff import *\n",
    "from kernel import Kernel\n",
    "\n",
    "# Multiprocessing\n",
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd94ff4d-5adc-424e-9532-8683becc50ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(num_data):\n",
    "    # AWGN\n",
    "    v = 0.1*np.random.normal(0,1,num_data+2) \n",
    "\n",
    "    # Initial conditions\n",
    "    d_true =[0.1 , 0.1]\n",
    "    d = [d_true[0] + v[0], d_true[1] + v[1]]\n",
    "\n",
    "    # Grab new data\n",
    "    new_d_true = lambda d: d.append((0.8 - 0.5 * np.exp(-(d[-1]**2)))*d[-1] - (0.3 + 0.9*np.exp(-(d[-1]**2)))*d[-2] + 0.1*np.sin(np.pi*d[-1]))\n",
    "    for i in range(2,num_data+2):\n",
    "        new_d_true(d_true)\n",
    "        d.append(d_true[-1] + v[i])\n",
    "\n",
    "    u = np.hstack((np.array(d[0:num_data]).reshape(num_data,1),np.array(d[1:num_data+1]).reshape(num_data,1)))\n",
    "    d_true = d_true[2::]\n",
    "    d = d[2::]\n",
    "    return np.array(u), np.array(d),np.array(d_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d6b297e-e0ef-4d38-8731-0c492baed5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_data = 3000\n",
    "kernel = Kernel(3.73)\n",
    "K = 10 # K edge clients\n",
    "step_size = 0.09\n",
    "reg_coeff = 0.03\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da50cb4c-2a1a-44ac-afbf-5d0d19e7d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data prepocessing for K clients\n",
    "edges_u = []\n",
    "edges_d = []\n",
    "edges_d_true = []\n",
    "for k in range(K):\n",
    "    u,d,d_true = generate_data(num_data)\n",
    "    \n",
    "    edges_u.append(np.array(u))\n",
    "    edges_d.append(np.array(d))\n",
    "    edges_d_true.append(np.array(d_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ea2a1bf1-70ba-4b5d-b43a-acd308c27d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3000/3000 [00:01<00:00, 1977.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# Federated learning: Synchronous updating rule\n",
    "\n",
    "l = 50 # l updates for synchronous\n",
    "c =  np.ones(K).reshape(K,1)/K # edge weighting, for now, lets try that all data is being received synchronously\n",
    "D = 25 # Dictionary size\n",
    "A = 0 # 1 if asynchronous\n",
    "\n",
    "y = np.zeros(K)\n",
    "alpha = np.zeros((D,1))\n",
    "alphas = np.zeros((K,D))\n",
    "\n",
    "final_mse = []\n",
    "l_idx = 0\n",
    "err = np.array([])\n",
    "# nmse = lambda D_n, Phi_n: np.sum((D_n - Phi_n)**2)\n",
    "for i in tqdm(range(0,num_data)):\n",
    "    y_hat = np.zeros(K)\n",
    "    # Local updates\n",
    "    \n",
    "    for k in range(K):\n",
    "        u_k = edges_u[k][i:i+1]\n",
    "        d_k = edges_d[k][i:i+1]\n",
    "        d_true_k = edges_d_true[k][i:i+1]\n",
    "        if l_idx == 0:\n",
    "            err,alpha_k,delta = KLMS_RFF(u_k,d_true_k,kernel,step_size,D,alpha_0=alpha)\n",
    "        else:\n",
    "            err,alpha_k,delta = KLMS_RFF(u_k,d_true_k,kernel,step_size,D,alpha_0=alphas[k])    \n",
    "        alphas[k] = alpha_k[0]\n",
    "\n",
    "        mse += ((np.array(d_true_k) - np.array(d_k) + err)**2)/K\n",
    "\n",
    "        l_idx+=1\n",
    "        if l_idx == l:\n",
    "            break\n",
    "    final_mse.append(mse[0])\n",
    "    mse = 0\n",
    "    if l_idx == l:\n",
    "        # Global update\n",
    "#         y = A * y + (c @ y_hat.T)\n",
    "        alpha = (A * alpha) + (alphas.T @ c)\n",
    "        l_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1fac3c58-3480-429d-a7e6-93d546026038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated learning: Asynchronous updating rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d313e77b-29cf-4b8a-a2ea-5007b5202d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= np.zeros((3,4))\n",
    "a[0] = np.array([1,1,1,1])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68abe988-3064-4506-81df-1ffae74268a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "597eb1a4-55af-4a8c-b000-581bbafd3bc3",
   "metadata": {},
   "source": [
    "# Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a7b5cb-341c-4a9b-b05a-5e6c03a4c9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  8\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from knlms import *\n",
    "from krls import *\n",
    "from krls_rff import *\n",
    "from klms import *\n",
    "from klms_rff import *\n",
    "from kernel import Kernel\n",
    "\n",
    "# Multiprocessing\n",
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd94ff4d-5adc-424e-9532-8683becc50ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(num_data):\n",
    "    # AWGN\n",
    "    v = 0.1*np.random.normal(0,1,num_data+2) \n",
    "\n",
    "    # Initial conditions\n",
    "    d_true =[0.1 , 0.1]\n",
    "    d = [d_true[0] + v[0], d_true[1] + v[1]]\n",
    "\n",
    "    # Grab new data\n",
    "    new_d_true = lambda d: d.append((0.8 - 0.5 * np.exp(-(d[-1]**2)))*d[-1] - (0.3 + 0.9*np.exp(-(d[-1]**2)))*d[-2] + 0.1*np.sin(np.pi*d[-1]))\n",
    "    for i in range(2,num_data+2):\n",
    "        new_d_true(d_true)\n",
    "        d.append(d_true[-1] + v[i])\n",
    "\n",
    "    u = np.hstack((np.array(d[0:num_data]).reshape(num_data,1),np.array(d[1:num_data+1]).reshape(num_data,1)))\n",
    "    d_true = d_true[2::]\n",
    "    d = d[2::]\n",
    "    return np.array(u), np.array(d),np.array(d_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d6b297e-e0ef-4d38-8731-0c492baed5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_data = 3000\n",
    "kernel = Kernel(3.73)\n",
    "K = 10 # K edge clients\n",
    "step_size = 0.09\n",
    "reg_coeff = 0.03\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da50cb4c-2a1a-44ac-afbf-5d0d19e7d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data prepocessing for K clients\n",
    "edges_X = []\n",
    "edges_y = []\n",
    "for k in range(K):\n",
    "    u,d,d_true = generate_data(num_data)\n",
    "    \n",
    "    edges_X.append(np.array(u))\n",
    "    edges_y.append(np.array(d_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea2a1bf1-70ba-4b5d-b43a-acd308c27d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/3000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jw/wg30js3108n731h_w_zpf3zw0000gn/T/ipykernel_3492/2975735579.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0merr_KLMS_RFF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKLMS_RFF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_true_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m#         y_hat[k] = alpha.T @ delta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0ml_idx\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# Federated learning: Synchronous updating rule\n",
    "\n",
    "l = 50 # l updates for synchronous\n",
    "c =  np.ones(K)/K # edge weighting, for now, lets try that all data is being received synchronously\n",
    "D = 25 # Dictionary size\n",
    "A = 0 # 1 if asynchronous\n",
    "\n",
    "y = np.zeros(K)\n",
    "alpha = np.zeros((D,1))\n",
    "alphas = []\n",
    "\n",
    "l_idx = 0\n",
    "\n",
    "for i in tqdm(range(0,num_data)):\n",
    "    y_hat = np.zeros(K)\n",
    "    # Local updates\n",
    "\n",
    "    for k in range(K):\n",
    "        u_k = edges_X[k][i:i+1]\n",
    "        d_true_k = edges_y[k][i:i+1]\n",
    "        if l_idx == 0:\n",
    "            err_KLMS_RFF,alpha_k,delta = KLMS_RFF(u_k,d_true_k,kernel,step_size,D,alpha_0=alpha)\n",
    "        else:\n",
    "            err_KLMS_RFF,alpha_k,delta = KLMS_RFF(u_k,d_true_k,kernel,step_size,D,alpha_0=alphas[k])        \n",
    "        alphas[k] = alpha_k \n",
    "#         y_hat[k] = alpha.T @ delta\n",
    "        l_idx+=1\n",
    "        if l_idx == l:\n",
    "            break\n",
    "    \n",
    "    if l_idx == l:\n",
    "        # Global update\n",
    "#         y = A * y + (c @ y_hat.T)\n",
    "        alpha = A * alpha + (c @ alphas.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1fac3c58-3480-429d-a7e6-93d546026038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated learning: Asynchronous updating rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d313e77b-29cf-4b8a-a2ea-5007b5202d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "j 4\n",
      "j 5\n",
      "hit\n",
      "i 1\n",
      "j 4\n",
      "j 5\n",
      "hit\n",
      "i 2\n",
      "j 4\n",
      "j 5\n",
      "hit\n",
      "i 3\n",
      "j 4\n",
      "j 5\n",
      "hit\n"
     ]
    }
   ],
   "source": [
    "for i in [0,1,2,3]:\n",
    "    print('i',i)\n",
    "    for j in [4,5,6,7]:\n",
    "        print('j',j)\n",
    "        if j==5:\n",
    "            print('hit')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68abe988-3064-4506-81df-1ffae74268a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
